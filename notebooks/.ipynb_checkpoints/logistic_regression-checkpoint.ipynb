{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a23a75",
   "metadata": {},
   "source": [
    "# Logistic Regression - Bank Marketing Campaign Prediction\n",
    "\n",
    "**Objective:** Build a Logistic Regression model to predict term deposit subscription.\n",
    "\n",
    "**Algorithm:** Logistic Regression - A linear model for binary classification that estimates probabilities using the logistic function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d5273",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6731c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, confusion_matrix,\n",
    "    classification_report, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216bbd8c",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56905b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../bank-additional-full.csv', sep=';')\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b559f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data info and missing values\n",
    "print(\"Data Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Duplicates:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c2ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df_clean = df.drop_duplicates()\n",
    "print(f\"Shape after removing duplicates: {df_clean.shape}\")\n",
    "\n",
    "# Statistical summary\n",
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824f156a",
   "metadata": {},
   "source": [
    "## 3. Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b005c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie chart\n",
    "target_counts = df_clean['y'].value_counts()\n",
    "axes[0].pie(target_counts, labels=target_counts.index, autopct='%1.1f%%', \n",
    "            startangle=90, colors=['#ff9999', '#66b3ff'])\n",
    "axes[0].set_title('Target Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bar chart\n",
    "sns.countplot(data=df_clean, x='y', palette='Set2', ax=axes[1])\n",
    "axes[1].set_title('Target Count', fontsize=14, fontweight='bold')\n",
    "for container in axes[1].containers:\n",
    "    axes[1].bar_label(container)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Class Distribution:\\n{df_clean['y'].value_counts()}\")\n",
    "print(f\"\\nClass Ratio:\\n{df_clean['y'].value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36c50e8",
   "metadata": {},
   "source": [
    "## 4. Key Feature Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620e9889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age and Duration distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(df_clean['age'], bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Age Distribution', fontweight='bold')\n",
    "axes[0].set_xlabel('Age')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1].hist(df_clean['duration'], bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_title('Call Duration Distribution', fontweight='bold')\n",
    "axes[1].set_xlabel('Duration (seconds)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3163bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subscription rate by key features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "categorical_features = ['job', 'marital', 'education', 'contact']\n",
    "\n",
    "for idx, col in enumerate(categorical_features):\n",
    "    ct = pd.crosstab(df_clean[col], df_clean['y'], normalize='index') * 100\n",
    "    ct.plot(kind='bar', ax=axes[idx], color=['#ff9999', '#66b3ff'])\n",
    "    axes[idx].set_title(f'Subscription Rate by {col.upper()}', fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col.capitalize())\n",
    "    axes[idx].set_ylabel('Percentage (%)')\n",
    "    axes[idx].legend(title='Subscribed', labels=['No', 'Yes'])\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6429a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "df_corr = df_clean.copy()\n",
    "df_corr['y_encoded'] = df_corr['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "numeric_cols = df_corr.select_dtypes(include=[np.number]).columns\n",
    "corr_matrix = df_corr[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            cbar_kws={'label': 'Correlation'}, linewidths=0.5)\n",
    "plt.title('Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop correlations with target:\")\n",
    "print(corr_matrix['y_encoded'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d742ef05",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca4dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target\n",
    "df_clean['y'] = df_clean['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Separate features and target\n",
    "X = df_clean.drop('y', axis=1)\n",
    "y = df_clean['y']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b43f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify column types\n",
    "numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "print(f\"Numerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "print(f\"\\nCategorical columns ({len(categorical_cols)}): {categorical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3492e334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "print(\"‚úÖ Preprocessing pipeline created\")\n",
    "print(\"   - Numerical: StandardScaler\")\n",
    "print(\"   - Categorical: OneHotEncoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e39b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Testing set: {X_test.shape}\")\n",
    "print(f\"\\nTrain target distribution:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"\\nTest target distribution:\\n{y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72214c7d",
   "metadata": {},
   "source": [
    "## 6. Model Training - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dfa80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train model\n",
    "print(\"ü§ñ Training Logistic Regression...\")\n",
    "\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6090cb81",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df86065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üìä LOGISTIC REGRESSION PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945bf9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e574b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics Visualization\n",
    "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "metrics_values = [accuracy, precision, recall, f1, roc_auc]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(metrics_names, metrics_values, color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6'], alpha=0.8)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.ylabel('Score', fontsize=12, fontweight='bold')\n",
    "plt.title('Logistic Regression - Performance Metrics', fontsize=14, fontweight='bold')\n",
    "plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Baseline (0.5)')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, value) in enumerate(zip(bars, metrics_values)):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "             f'{value:.4f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b7af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics Summary Table\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'],\n",
    "    'Score': [accuracy, precision, recall, f1, roc_auc],\n",
    "    'Interpretation': [\n",
    "        'Overall correctness of predictions',\n",
    "        'Accuracy of positive predictions',\n",
    "        'Coverage of actual positive cases',\n",
    "        'Harmonic mean of Precision & Recall',\n",
    "        'Model discrimination ability'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nüìä DETAILED METRICS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(metrics_df.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f141bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation score\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"\\nüîÑ Cross-Validation ROC-AUC Scores: {cv_scores}\")\n",
    "print(f\"Mean CV ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591e62d1",
   "metadata": {},
   "source": [
    "## 8. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da4720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No', 'Yes'])\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Logistic Regression - Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"True Negatives:  {cm[0,0]}\")\n",
    "print(f\"False Positives: {cm[0,1]}\")\n",
    "print(f\"False Negatives: {cm[1,0]}\")\n",
    "print(f\"True Positives:  {cm[1,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26fcfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'Logistic Regression (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
    "plt.title('ROC Curve - Logistic Regression', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e88da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Coefficients\n",
    "cat_transformer = model.named_steps['preprocessor'].transformers_[1][1]\n",
    "cat_feature_names = cat_transformer.get_feature_names_out(categorical_cols)\n",
    "all_features = numerical_cols + list(cat_feature_names)\n",
    "\n",
    "coefficients = model.named_steps['classifier'].coef_[0]\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': all_features,\n",
    "    'Coefficient': coefficients\n",
    "}).sort_values('Coefficient', key=abs, ascending=False).head(20)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['red' if x < 0 else 'green' for x in coef_df['Coefficient']]\n",
    "plt.barh(range(len(coef_df)), coef_df['Coefficient'], color=colors, alpha=0.7)\n",
    "plt.yticks(range(len(coef_df)), coef_df['Feature'])\n",
    "plt.xlabel('Coefficient Value', fontsize=12, fontweight='bold')\n",
    "plt.title('Top 20 Feature Coefficients', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Positive Coefficients (Increase subscription probability):\")\n",
    "print(coef_df[coef_df['Coefficient'] > 0].head(10))\n",
    "print(\"\\nTop 10 Negative Coefficients (Decrease subscription probability):\")\n",
    "print(coef_df[coef_df['Coefficient'] < 0].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0a178a",
   "metadata": {},
   "source": [
    "## 9. Prediction Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e55daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample customer data\n",
    "sample_customer = pd.DataFrame({\n",
    "    'age': [35],\n",
    "    'job': ['admin.'],\n",
    "    'marital': ['married'],\n",
    "    'education': ['university.degree'],\n",
    "    'default': ['no'],\n",
    "    'housing': ['yes'],\n",
    "    'loan': ['no'],\n",
    "    'contact': ['cellular'],\n",
    "    'month': ['may'],\n",
    "    'day_of_week': ['mon'],\n",
    "    'duration': [300],\n",
    "    'campaign': [2],\n",
    "    'pdays': [999],\n",
    "    'previous': [0],\n",
    "    'poutcome': ['nonexistent'],\n",
    "    'emp.var.rate': [1.1],\n",
    "    'cons.price.idx': [93.994],\n",
    "    'cons.conf.idx': [-36.4],\n",
    "    'euribor3m': [4.857],\n",
    "    'nr.employed': [5191.0]\n",
    "})\n",
    "\n",
    "print(\"üìã Sample Customer Profile:\")\n",
    "print(\"=\"*60)\n",
    "for col, val in sample_customer.iloc[0].items():\n",
    "    print(f\"{col:20s}: {val}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2bed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "prediction = model.predict(sample_customer)[0]\n",
    "probability = model.predict_proba(sample_customer)[0]\n",
    "\n",
    "print(\"\\nüîÆ PREDICTION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Prediction: {'‚úÖ YES - Will Subscribe' if prediction == 1 else '‚ùå NO - Will Not Subscribe'}\")\n",
    "print(f\"\\nProbabilities:\")\n",
    "print(f\"  No (0):  {probability[0]:.4f} ({probability[0]*100:.2f}%)\")\n",
    "print(f\"  Yes (1): {probability[1]:.4f} ({probability[1]*100:.2f}%)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualize probability\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "colors = ['#ff9999', '#66b3ff']\n",
    "bars = ax.bar(['No', 'Yes'], probability, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax.set_ylabel('Probability', fontweight='bold', fontsize=12)\n",
    "ax.set_title('Subscription Probability for Sample Customer', fontweight='bold', fontsize=14)\n",
    "ax.set_ylim([0, 1])\n",
    "ax.axhline(y=0.5, color='red', linestyle='--', linewidth=1, label='Decision Threshold')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.4f}\\n({height*100:.2f}%)',\n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a8512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch prediction example with multiple customers\n",
    "batch_customers = pd.DataFrame({\n",
    "    'age': [25, 45, 60],\n",
    "    'job': ['student', 'admin.', 'retired'],\n",
    "    'marital': ['single', 'married', 'married'],\n",
    "    'education': ['university.degree', 'high.school', 'basic.4y'],\n",
    "    'default': ['no', 'no', 'no'],\n",
    "    'housing': ['no', 'yes', 'yes'],\n",
    "    'loan': ['no', 'no', 'no'],\n",
    "    'contact': ['cellular', 'cellular', 'telephone'],\n",
    "    'month': ['may', 'jul', 'aug'],\n",
    "    'day_of_week': ['thu', 'tue', 'mon'],\n",
    "    'duration': [180, 350, 120],\n",
    "    'campaign': [1, 2, 3],\n",
    "    'pdays': [999, 999, 999],\n",
    "    'previous': [0, 1, 0],\n",
    "    'poutcome': ['nonexistent', 'success', 'nonexistent'],\n",
    "    'emp.var.rate': [1.1, 1.4, -0.1],\n",
    "    'cons.price.idx': [93.994, 94.465, 93.200],\n",
    "    'cons.conf.idx': [-36.4, -41.8, -42.0],\n",
    "    'euribor3m': [4.857, 4.959, 1.313],\n",
    "    'nr.employed': [5191.0, 5228.1, 5099.1]\n",
    "})\n",
    "\n",
    "batch_predictions = model.predict(batch_customers)\n",
    "batch_probabilities = model.predict_proba(batch_customers)[:, 1]\n",
    "\n",
    "results_df = batch_customers[['age', 'job', 'education', 'duration']].copy()\n",
    "results_df['Prediction'] = ['Yes' if p == 1 else 'No' for p in batch_predictions]\n",
    "results_df['Probability_Yes'] = batch_probabilities\n",
    "\n",
    "print(\"\\nüìä BATCH PREDICTION RESULTS (3 Customers)\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7187d3",
   "metadata": {},
   "source": [
    "## 10. Key Insights & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ec5831",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üîç LOGISTIC REGRESSION - KEY INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ MODEL PERFORMANCE:\")\n",
    "print(f\"   - ROC-AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"   - Accuracy: {accuracy:.4f}\")\n",
    "print(f\"   - F1-Score: {f1:.4f}\")\n",
    "print(f\"   - Model is {'well-calibrated' if 0.7 <= roc_auc <= 0.85 else 'needs tuning'}\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ TOP POSITIVE FEATURES (Increase subscription):\")\n",
    "top_positive = coef_df[coef_df['Coefficient'] > 0].head(5)\n",
    "for idx, row in top_positive.iterrows():\n",
    "    print(f\"   ‚úÖ {row['Feature']}: {row['Coefficient']:.4f}\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ TOP NEGATIVE FEATURES (Decrease subscription):\")\n",
    "top_negative = coef_df[coef_df['Coefficient'] < 0].head(5)\n",
    "for idx, row in top_negative.iterrows():\n",
    "    print(f\"   ‚ùå {row['Feature']}: {row['Coefficient']:.4f}\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ BUSINESS RECOMMENDATIONS:\")\n",
    "print(\"   üìû Focus on longer call durations - strong positive predictor\")\n",
    "print(\"   üì± Prioritize cellular contact over telephone\")\n",
    "print(\"   üìä Target customers based on economic indicators\")\n",
    "print(\"   üéØ Use probability scores to prioritize high-likelihood prospects\")\n",
    "\n",
    "print(\"\\n5Ô∏è‚É£ MODEL STRENGTHS:\")\n",
    "print(\"   ‚úÖ Interpretable - coefficients show feature impact\")\n",
    "print(\"   ‚úÖ Fast training and prediction\")\n",
    "print(\"   ‚úÖ Provides probability estimates\")\n",
    "print(\"   ‚úÖ Good baseline for comparison with complex models\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
